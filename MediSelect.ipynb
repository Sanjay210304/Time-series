{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 97258,
          "sourceType": "competition"
        },
        {
          "sourceId": 7536020,
          "sourceType": "datasetVersion",
          "datasetId": 4388604
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "MediSelect",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "blueblushed_hospital_dataset_for_practice_path = kagglehub.dataset_download('blueblushed/hospital-dataset-for-practice')\n",
        "google_gemini_2_0_flash_api_api_gemini_2_0_flash_1_path = kagglehub.model_download('google/gemini-2.0-flash-api/Api/gemini-2.0-flash/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ei0vTA3qHdCJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:00.356756Z",
          "iopub.execute_input": "2025-04-17T14:34:00.357091Z",
          "iopub.status.idle": "2025-04-17T14:34:00.365499Z",
          "shell.execute_reply.started": "2025-04-17T14:34:00.357068Z",
          "shell.execute_reply": "2025-04-17T14:34:00.364592Z"
        },
        "id": "Pr_9FKgrHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing libraries"
      ],
      "metadata": {
        "id": "dviCakCuHdCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google\"\n",
        "!pip install -U -q \"google.genai\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:00.367323Z",
          "iopub.execute_input": "2025-04-17T14:34:00.367607Z",
          "iopub.status.idle": "2025-04-17T14:34:09.177952Z",
          "shell.execute_reply.started": "2025-04-17T14:34:00.367587Z",
          "shell.execute_reply": "2025-04-17T14:34:09.176324Z"
        },
        "id": "wt6R32rIHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-google-genai google-generativeai\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:09.17955Z",
          "iopub.execute_input": "2025-04-17T14:34:09.179956Z",
          "iopub.status.idle": "2025-04-17T14:34:13.861654Z",
          "shell.execute_reply.started": "2025-04-17T14:34:09.179922Z",
          "shell.execute_reply": "2025-04-17T14:34:13.860436Z"
        },
        "id": "KnId9UnbHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "j3yvAjIPHdCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "from langchain.agents import Tool, AgentExecutor, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:13.864569Z",
          "iopub.execute_input": "2025-04-17T14:34:13.864934Z",
          "iopub.status.idle": "2025-04-17T14:34:13.872176Z",
          "shell.execute_reply.started": "2025-04-17T14:34:13.864904Z",
          "shell.execute_reply": "2025-04-17T14:34:13.871235Z"
        },
        "id": "jBitvA6dHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seting API Key"
      ],
      "metadata": {
        "id": "YYDi9GgSHdCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_secrets = UserSecretsClient()\n",
        "secret_value_0 = user_secrets.get_secret(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:13.875034Z",
          "iopub.execute_input": "2025-04-17T14:34:13.876488Z",
          "iopub.status.idle": "2025-04-17T14:34:14.02882Z",
          "shell.execute_reply.started": "2025-04-17T14:34:13.876448Z",
          "shell.execute_reply": "2025-04-17T14:34:14.027439Z"
        },
        "id": "ezPXnPLaHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.agents import Tool, AgentExecutor, initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google import genai\n",
        "from google.genai import types"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:14.029926Z",
          "iopub.execute_input": "2025-04-17T14:34:14.03042Z",
          "iopub.status.idle": "2025-04-17T14:34:14.03694Z",
          "shell.execute_reply.started": "2025-04-17T14:34:14.03038Z",
          "shell.execute_reply": "2025-04-17T14:34:14.03581Z"
        },
        "id": "0Oq_m1YYHdCM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Function"
      ],
      "metadata": {
        "id": "GepdmOo3HdCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 1. RAG Function ------------------\n",
        "def generate_rag_response(user_text: str) -> str:\n",
        "    client = genai.Client(api_key=secret_value_0)\n",
        "\n",
        "    uploaded_file = client.files.upload(file=\"/kaggle/input/hospital-dataset-for-practice/hospital data analysis.csv\")  # Adjust path if needed\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=uploaded_file.uri,\n",
        "                    mime_type=uploaded_file.mime_type,\n",
        "                ),\n",
        "                types.Part.from_text(text=f\"\"\"You are a helpful assistant. Use the data in the file to answer this question directly and also note that the data which you present should be detailed. The user input is: {user_text}\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    config = types.GenerateContentConfig(response_mime_type=\"text/plain\")\n",
        "\n",
        "    try:\n",
        "        rag_response = \"\"\n",
        "        for chunk in client.models.generate_content_stream(\n",
        "            model=\"gemini-2.0-flash-lite\",\n",
        "            contents=contents,\n",
        "            config=config,\n",
        "        ):\n",
        "            rag_response += chunk.text\n",
        "        return rag_response\n",
        "    except genai.errors.ClientError as e:\n",
        "        return \"RAG failed to retrieve data.\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:14.038155Z",
          "iopub.execute_input": "2025-04-17T14:34:14.038505Z",
          "iopub.status.idle": "2025-04-17T14:34:14.060076Z",
          "shell.execute_reply.started": "2025-04-17T14:34:14.038474Z",
          "shell.execute_reply": "2025-04-17T14:34:14.058168Z"
        },
        "id": "tHirI4DUHdCN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 2. Set up LangChain LLM ------------------\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash-latest\",\n",
        "    temperature=0.7,\n",
        "    verbose=True,\n",
        "    api_key=secret_value_0\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:14.061382Z",
          "iopub.execute_input": "2025-04-17T14:34:14.061834Z",
          "iopub.status.idle": "2025-04-17T14:34:14.091487Z",
          "shell.execute_reply.started": "2025-04-17T14:34:14.061806Z",
          "shell.execute_reply": "2025-04-17T14:34:14.090312Z"
        },
        "id": "iFyU6DmcHdCN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Tool or Function Calling"
      ],
      "metadata": {
        "id": "m-D4iBMxHdCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 3. Define Tool for RAG ------------------\n",
        "def rag_tool_func(query: str) -> str:\n",
        "    return generate_rag_response(query)\n",
        "\n",
        "rag_tool = Tool(\n",
        "    name=\"RAGDataSearch\",\n",
        "    func=rag_tool_func,\n",
        "    description=\"Use this tool to retrieve detailed hospital or organization data from a CSV based on user query.\"\n",
        ")\n",
        "\n",
        "# ----------------- 4. Agent Setup ------------------\n",
        "tools = [rag_tool]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,handle_parsing_errors = True)\n",
        "\n",
        "# Function to process the prompt with the agent\n",
        "def process_prompt_with_agent(prompt):\n",
        "    return agent.run(prompt)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:14.09248Z",
          "iopub.execute_input": "2025-04-17T14:34:14.092839Z",
          "iopub.status.idle": "2025-04-17T14:34:14.118531Z",
          "shell.execute_reply.started": "2025-04-17T14:34:14.09281Z",
          "shell.execute_reply": "2025-04-17T14:34:14.117288Z"
        },
        "id": "9-titU1tHdCN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG & Agent Invocation with query"
      ],
      "metadata": {
        "id": "gjjZmaRcHdCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 5. Run Agent ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    user_input = \"I am suffering from Appendicitis will I get cured?\"  # Sample User Input\n",
        "    # user_input = input(\"ðŸ’¬ Please enter your question: \")\n",
        "    print(\"\\nðŸ§  Agent reasoning and decision in progress...\\n\")\n",
        "    # Call the rag_tool function to get the response before using it in the prompt\n",
        "    response = rag_tool_func(user_input)\n",
        "    text = user_input\n",
        "\n",
        "    # Now define the prompt with 'text' and 'response' available\n",
        "    # Used few shot prompting technique.\n",
        "    prompt = f\"\"\"You are a helpful assistant to recommend a hospital or not for a user based on their records.\n",
        "      You don't have any tools.\n",
        "      You are given an input from the user: {text} and a response from RAG: {response}.\n",
        "      The RAG response includes satisfaction scores and various columns based on a hospital or organization.\n",
        "      Based on the RAG data, your job is to analyze it and say whether the user should take an appointment or not in that hospital.\n",
        "      The ouput should be strictly be with a justification:\n",
        "      Example 1:\n",
        "      Yes, according to the data given you can reach out to the particular hospital or organisation.\n",
        "      Example 2: No, according to the data given you cannot reach out to the particular hospital or organisation.\n",
        "      Example 3: Not sure, according to the data it is difficult to understand whether to go to the particular hospital or organisation or not.\n",
        "    \"\"\"\n",
        "    # Run the agent with the updated prompt that includes text and response\n",
        "    output = agent.run(prompt)\n",
        "\n",
        "    print(\"\\nâœ… Final Recommendation:\\n\", output)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:36.478423Z",
          "iopub.execute_input": "2025-04-17T14:34:36.478768Z",
          "iopub.status.idle": "2025-04-17T14:34:57.787847Z",
          "shell.execute_reply.started": "2025-04-17T14:34:36.478743Z",
          "shell.execute_reply": "2025-04-17T14:34:57.786449Z"
        },
        "id": "YJDTIooOHdCN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 2"
      ],
      "metadata": {
        "id": "xWV0-4TGHdCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 5. Run Agent ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    user_input = \"How many days should a person admit for if he is suffering from Fractured Leg?\" # Sample User Input\n",
        "    # user_input = input(\"ðŸ’¬ Please enter your question: \")\n",
        "    print(\"\\nðŸ§  Agent reasoning and decision in progress...\\n\")\n",
        "    # Call the rag_tool function to get the response before using it in the prompt\n",
        "    response = rag_tool_func(user_input)\n",
        "    # Assign the user input to the 'text' variable\n",
        "    text = user_input\n",
        "\n",
        "    # Now define the prompt with 'text' and 'response' available\n",
        "    # Used few shot prompting technique.\n",
        "    prompt = f\"\"\"You are a helpful assistant to recommend a hospital or not for a user based on their records.\n",
        "      You don't have any tools.\n",
        "      You are given an input from the user: {text} and a response from RAG: {response}.\n",
        "      The RAG response includes satisfaction scores and various columns based on a hospital or organization.\n",
        "      Based on the RAG data, your job is to analyze it and say whether the user should take an appointment or not in that hospital.\n",
        "      The ouput should be strictly be with a justification:\n",
        "      Example 1:\n",
        "      Yes, according to the data given you can reach out to the particular hospital or organisation.\n",
        "      Example 2: No, according to the data given you cannot reach out to the particular hospital or organisation.\n",
        "      Example 3: Not sure, according to the data it is difficult to understand whether to go to the particular hospital or organisation or not.\n",
        "    \"\"\"\n",
        "    # Run the agent with the updated prompt that includes text and response\n",
        "    output = agent.run(prompt)\n",
        "\n",
        "    print(\"\\nâœ… Final Recommendation:\\n\", output)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T14:34:57.790577Z",
          "iopub.execute_input": "2025-04-17T14:34:57.790916Z",
          "iopub.status.idle": "2025-04-17T14:35:06.270712Z",
          "shell.execute_reply.started": "2025-04-17T14:34:57.790894Z",
          "shell.execute_reply": "2025-04-17T14:35:06.269617Z"
        },
        "id": "DGEA_9u1HdCN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}